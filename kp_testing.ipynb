{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/test_geometric_features_normalized.csv')\n",
    "# df2=pd.read_csv('geometric_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearity             740\n",
      "planarity             740\n",
      "sphericity            740\n",
      "omnivariance          740\n",
      "anisotropy            740\n",
      "eigenentropy          740\n",
      "sum_of_eigenvalues    740\n",
      "change_curvature      740\n",
      "id                    740\n",
      "class                  12\n",
      "reflectance            19\n",
      "dtype: int64\n",
      "anisotropy            2438\n",
      "change_curvature      2438\n",
      "eigenentropy          2438\n",
      "linearity             2438\n",
      "omnivariance          2438\n",
      "planarity             2438\n",
      "sphericity            2438\n",
      "sum_of_eigenvalues    2438\n",
      "class                   47\n",
      "reflectance             37\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/state/partition1/job-16060395/ipykernel_2947353/834112461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# result = loaded_model.score(X_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#testing saved ML models \n",
    "\n",
    "# scaler = StandardScaler()\n",
    "X_test=pd.read_csv('../X_test.csv')\n",
    "y_test=pd.read_csv('../y_test.csv')\n",
    "y_test=y_test['true_labels'].to_numpy()\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_test=(X_test-X_test.mean())/X_test.std()\n",
    "# print(X_test.shape)\n",
    "filename = 'knn.sav'\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing saved DL models\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import trimesh\n",
    "from plyfile import PlyData, PlyElement\n",
    "import open3d as o3d\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay,classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "points = []\n",
    "labels = []\n",
    "\n",
    "for file in glob.glob('../data/sampled_ply/*.ply'):\n",
    "# for file in glob.glob('paris_lille/sampled_ply/*.ply'):    \n",
    "    \n",
    "#     print(file)\n",
    "    label = file.split('/')[-1].split('_')[2]\n",
    "#     print(label)\n",
    "    ply = PlyData.read(file)\n",
    "    data = ply.elements[0].data\n",
    "    data_pd = pd.DataFrame(data)\n",
    "    data_np = np.zeros(data_pd.shape, dtype=np.float)\n",
    "    property_names = data[0].dtype.names\n",
    "    \n",
    "    for i, name in enumerate(property_names):\n",
    "        data_np[:,i] = data_pd[name]\n",
    "        \n",
    "    data_np = data_np[:,:3]    \n",
    "    data_np = preprocessing.minmax_scale(data_np)\n",
    "    \n",
    "    points.append(data_np)\n",
    "    labels.append(label)\n",
    "object_classes = {\n",
    "    '0' : 'Unclassified',\n",
    "    '100000000' : 'Other',\n",
    "    '200000000' : 'Surface',\n",
    "    '201000000' : 'Other Surface',\n",
    "    '202000000' : 'Ground',\n",
    "    '202010000' : 'Other Ground',\n",
    "    '202020000' : 'Road',\n",
    "    '202030000' : 'Sidewalk',\n",
    "    '202040000' : 'Curb',\n",
    "    '202050000' : 'Island',\n",
    "    '202060000' : 'Vegetation',\n",
    "    '203000000' : 'Building',\n",
    "    '300000000' : 'Object',\n",
    "    '301000000' : 'Other Object',\n",
    "    '302000000' : 'Static',\n",
    "    '302010000' : 'Other Static',\n",
    "    '302020000' : 'Punctual Object',\n",
    "    '302020100' : 'Other Punctual Object',\n",
    "    '302020200' : 'Post',\n",
    "    '302020300' : 'Bollard',\n",
    "    '302020400' : 'Floor Lamp',\n",
    "    '302020500' : 'Traffic Light',\n",
    "    '302020600' : 'Traffic Sign',\n",
    "    '302020700' : 'Signboard',\n",
    "    '302020800' : 'Mailbox',\n",
    "    '302020900' : 'Trash Can',\n",
    "    '302021000' : 'Meter',\n",
    "    '302021100' : 'Bicycle Terminal',\n",
    "    '302021200' : 'Bicycle Rack',\n",
    "    '302021300' : 'Statue',\n",
    "    '302030000' : 'Linear',\n",
    "    '302030100' : 'Other Linear',\n",
    "    '302030200' : 'Barrier',\n",
    "    '302030300' : 'Roasting',\n",
    "    '302030400' : 'Grid',\n",
    "    '302030500' : 'Chain',\n",
    "    '302030600' : 'Wire',\n",
    "    '302030700' : 'Low Wall',\n",
    "    '302040000' : 'Extended',\n",
    "    '302040100' : 'Other Extended',\n",
    "    '302040200' : 'Shelter',\n",
    "    '302040300' : 'Kiosk',\n",
    "    '302040400' : 'Scaffold',\n",
    "    '302040500' : 'Bench',\n",
    "    '302040600' : 'Distribution Box',\n",
    "    '302040700' : 'Lighting Console',\n",
    "    '302040800' : 'Windmill',\n",
    "    '303000000' : 'Dynamic',\n",
    "    '303010000' : 'Other Dynamic',\n",
    "    '303020000' : 'Pedestrian',\n",
    "    '303020100' : 'Other Pedestrian',\n",
    "    '303020200' : 'Still Pedestrian',\n",
    "    '303020300' : 'Walking Pedestrian',\n",
    "    '303020400' : 'Running Pedestrian',\n",
    "    '303020500' : 'Stroller Pedestrian',\n",
    "    '303020600' : 'Holding Pedesterian',\n",
    "    '303020700' : 'Leaning Pedestrian',\n",
    "    '303020800' : 'Skater',\n",
    "    '303020900' : 'Rollerskater',\n",
    "    '303021000' : 'Wheelchair',\n",
    "    '303030000' : '2 Wheelers',\n",
    "    '303030100' : 'Other 2 Wheels',\n",
    "    '303030200' : 'Bicycle',\n",
    "    '303030201' : 'Other Bicycle',\n",
    "    '303030202' : 'Mobile Bicycle',\n",
    "    '303030203' : 'Stopped Bicycle',\n",
    "    '303030204' : 'Parked Bicycle',\n",
    "    '303030300' : 'Scooter',\n",
    "    '303030301' : 'Other Scooter',\n",
    "    '303030302' : 'Mobile Scooter',\n",
    "    '303030303' : 'Stopped Scooter',\n",
    "    '303030304' : 'Parked Scooter',\n",
    "    '303030400' : 'Moped',\n",
    "    '303030401' : 'Other Moped',\n",
    "    '303030402' : 'Mobile Moped',\n",
    "    '303030403' : 'Stopped Moped',\n",
    "    '303030404' : 'Parked Moped',\n",
    "    '303030500' : 'Motorbike',\n",
    "    '303030501' : 'Other Motorbike',\n",
    "    '303030502' : 'Mobile Motorbike',\n",
    "    '303030503' : 'Stopped Motorbike',\n",
    "    '303030504' : 'Parked Motorbike',\n",
    "    '303040000' : '4+ Wheelers',\n",
    "    '303040100' : 'Other 4+ Wheelers',\n",
    "    '303040200' : 'Car',\n",
    "    '303040201' : 'Other Car',\n",
    "    '303040202' : 'Mobile Car',\n",
    "    '303040203' : 'Stopped Car',\n",
    "    '303040204' : 'Parked Car',\n",
    "    '303040300' : 'Van',\n",
    "    '303040301' : 'Other Van',\n",
    "    '303040302' : 'Mobile Van',\n",
    "    '303040303' : 'Stopped Van',\n",
    "    '303040304' : 'Parked Van',\n",
    "    '303040400' : 'Truck',\n",
    "    '303040401' : 'Other Truck',\n",
    "    '303040402' : 'Mobile Truck',\n",
    "    '303040403' : 'Stopped Truck',\n",
    "    '303040404' : 'Parked Truck',\n",
    "    '303040500' : 'Bus',\n",
    "    '303040501' : 'Other Bus',\n",
    "    '303040502' : 'Mobile Bus',\n",
    "    '303040503' : 'Stopped Bus',\n",
    "    '303040504' : 'Parked Bus',\n",
    "    '303050000' : 'Furniture',\n",
    "    '303050100' : 'Other Furniture',\n",
    "    '303050200' : 'Table',\n",
    "    '303050300' : 'Chair',\n",
    "    '303050400' : 'Stool',\n",
    "    '303050500' : 'Trash Can',\n",
    "    '303050600' : 'Waste',\n",
    "    '304000000' : 'Natural',\n",
    "    '304010000' : 'Other Natural',\n",
    "    '304020000' : 'Tree',\n",
    "    '304030000' : 'Bush',\n",
    "    '304040000' : 'Potted Plant',\n",
    "    '304050000' : 'Hedge'\n",
    "}\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "labels = [object_classes.get(item,item) for item in labels]\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "mapping = {}\n",
    "keys = range(len(unique_labels))\n",
    "\n",
    "for i in keys:\n",
    "    mapping[i] = unique_labels[i]\n",
    "    \n",
    "rev_mapping = dict((v,k) for k,v in mapping.items())\n",
    "new_labels = [rev_mapping[i] for i in labels]\n",
    "\n",
    "\n",
    "# In[102]:\n",
    "\n",
    "\n",
    "## testing KP\n",
    "# print(keys)\n",
    "# print(unique_labels[0])\n",
    "# print(rev_mapping)\n",
    "# print(new_labels)\n",
    "# print(labels)\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "NUM_POINTS = 1000\n",
    "NUM_CLASSES = 48\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "# checking if gpu is available or not KP\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(points, new_labels, test_size=.33, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.15, random_state=0)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sean",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
